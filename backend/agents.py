"""
M√≥dulo de Integra√ß√£o Agno + Qdrant RAG
Gerenciamento de agentes IA com acesso controlado a bases de conhecimento
"""

import os
import json
import time
import logging
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Carregar vari√°veis de ambiente
load_dotenv()

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

from sqlalchemy.orm import Session
from sqlalchemy import text
from agent_models import AgentTeam, TeamMember, Agent as AgentModel

# Verificar se a API key est√° configurada
if not os.getenv('OPENAI_API_KEY'):
    raise ValueError("OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.")


class QdrantRAGTool:
    """
    Ferramenta customizada para integra√ß√£o Agno + Qdrant
    Permite que agentes busquem em cole√ß√µes espec√≠ficas
    """

    def __init__(self, qdrant_service, allowed_collections: List[str], db: Session):
        self.qdrant_service = qdrant_service
        self.allowed_collections = allowed_collections
        self.db = db
        self.search_history = []

    def search(self, query: str, collection_name: str = None, limit: int = 5) -> List[Dict]:
        """
        Busca sem√¢ntica em cole√ß√µes Qdrant permitidas

        Args:
            query: Pergunta ou termo de busca
            collection_name: Nome espec√≠fico da cole√ß√£o (opcional)
            limit: N√∫mero m√°ximo de resultados

        Returns:
            Lista de chunks relevantes com scores
        """
        logger.info(f"üîé [RAG] BUSCA INICIADA: '{query[:100]}...'")
        logger.info(f"üóÑÔ∏è [RAG] COLE√á√ïES PERMITIDAS: {self.allowed_collections}")
        
        # Validar acesso √† cole√ß√£o
        if collection_name and collection_name not in self.allowed_collections:
            error_msg = f"Acesso negado √† cole√ß√£o '{collection_name}'"
            logger.error(f"‚ùå [RAG] {error_msg}")
            return [{
                "error": error_msg,
                "allowed_collections": self.allowed_collections
            }]

        results = []
        collections_to_search = [collection_name] if collection_name else self.allowed_collections
        logger.info(f"üéØ [RAG] BUSCANDO EM: {collections_to_search}")

        # Buscar em cada cole√ß√£o permitida
        for coll_name in collections_to_search:
            try:
                logger.info(f"   üìö [RAG] BUSCANDO NA COLE√á√ÉO: {coll_name}")
                coll_results = self.qdrant_service.search_similar_chunks(
                    coll_name,
                    query,
                    limit
                )

                logger.info(f"   ‚úÖ [RAG] {len(coll_results)} resultados encontrados em {coll_name}")

                # Adicionar metadados da cole√ß√£o
                for result in coll_results:
                    result['collection'] = coll_name
                    result['search_query'] = query

                results.extend(coll_results)

            except Exception as e:
                logger.error(f"   ‚ùå [RAG] ERRO na cole√ß√£o {coll_name}: {e}")
                continue

        # Ordenar por score (maior primeiro)
        results.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        logger.info(f"üèÜ [RAG] TOTAL DE RESULTADOS: {len(results)} (limitado a {limit})")
        if results:
            logger.info(f"üìä [RAG] MELHOR SCORE: {results[0].get('score', 0):.4f}")

        # Registrar busca
        search_record = {
            "query": query,
            "collections_searched": collections_to_search,
            "results_count": len(results),
            "timestamp": datetime.now().isoformat(),
            "top_results": [{"content": r.get('text', '')[:200] + '...', "score": r.get('score', 0)} for r in results[:3]]
        }
        self.search_history.append(search_record)

        final_results = results[:limit]
        logger.info(f"‚úÖ [RAG] RETORNANDO {len(final_results)} RESULTADOS FINAIS")
        
        # Log para captura posterior na UI
        if final_results:
            logger.info(f"üìã [RAG-RESULTS] QUERY: {query[:100]}")
            logger.info(f"üìã [RAG-RESULTS] COLLECTIONS: {collections_to_search}")
            logger.info(f"üìã [RAG-RESULTS] COUNT: {len(final_results)}")
            for i, result in enumerate(final_results[:3]):
                logger.info(f"üìã [RAG-RESULTS] #{i+1}: {result.get('text', '')[:150]}... (score: {result.get('score', 0):.3f})")
        
        return final_results

    def get_collection_stats(self, collection_name: str) -> Dict:
        """Obter estat√≠sticas de uma cole√ß√£o"""
        if collection_name not in self.allowed_collections:
            return {"error": "Acesso negado"}

        return self.qdrant_service.get_collection_info(collection_name)


class AgentManager:
    """
    Gerenciador central de agentes Agno
    Respons√°vel por criar, configurar e executar agentes
    """

    def __init__(self, db: Session, qdrant_service):
        self.db = db
        self.qdrant_service = qdrant_service
        self.active_agents = {}  # Cache de agentes ativos
        self.execution_history = []

    def get_agent_collections(self, agent_id: int) -> List[Dict]:
        """
        Retorna cole√ß√µes que o agente pode acessar com seus n√≠veis de permiss√£o
        """
        logger.info(f"üîç [AGENT-{agent_id}] BUSCANDO COLE√á√ïES RAG ASSOCIADAS...")
        
        query = text("""
            SELECT c.name, c.id, ac.access_level, ac.priority
            FROM collections c
            JOIN agent_collections ac ON c.id = ac.collection_id
            WHERE ac.agent_id = :agent_id
            ORDER BY ac.priority DESC
        """)

        result = self.db.execute(query, {"agent_id": agent_id})
        collections = []

        for row in result:
            collection_data = {
                "name": row.name,
                "id": row.id,
                "access_level": row.access_level,
                "priority": row.priority
            }
            collections.append(collection_data)
            logger.info(f"   üìö [AGENT-{agent_id}] COLE√á√ÉO: {row.name} (ID: {row.id}) - Acesso: {row.access_level}, Prioridade: {row.priority}")

        if not collections:
            logger.warning(f"‚ö†Ô∏è [AGENT-{agent_id}] NENHUMA COLE√á√ÉO RAG ENCONTRADA")
        else:
            logger.info(f"‚úÖ [AGENT-{agent_id}] ENCONTRADAS {len(collections)} COLE√á√ïES RAG")

        return collections

    def create_agent_instance(self, agent_config: Dict) -> Agent:
        """
        Cria inst√¢ncia configurada de um agente Agno
        """
        agent_id = agent_config.get('id')

        # Verificar cache
        if agent_id in self.active_agents:
            return self.active_agents[agent_id]

        # Buscar cole√ß√µes permitidas
        agent_collections = self.get_agent_collections(agent_id)
        allowed_collection_names = [c['name'] for c in agent_collections]

        # Criar ferramenta RAG customizada
        rag_tool = QdrantRAGTool(
            self.qdrant_service,
            allowed_collection_names,
            self.db
        )

        # Configurar ferramentas do agente
        tools = []

        # RAG √© sempre inclu√≠do
        tools.append(rag_tool.search)

        # Adicionar ferramentas extras conforme configura√ß√£o
        tools_config = agent_config.get('tools_config', [])

        if isinstance(tools_config, str):
            tools_config = json.loads(tools_config) if tools_config else []

        if 'web_search' in tools_config:
            tools.append(DuckDuckGoTools())

        if 'reasoning' in tools_config:
            tools.append(ReasoningTools())

        # Preparar instru√ß√µes com contexto das cole√ß√µes
        base_instructions = agent_config.get('instructions', '')

        if allowed_collection_names:
            logger.info(f"üìã [AGENT-{agent_id}] ADICIONANDO CONTEXTO RAG √ÄS INSTRU√á√ïES")
            collections_context = f"""
üóÑÔ∏è BASES DE CONHECIMENTO DISPON√çVEIS:
{chr(10).join([f"‚Ä¢ {name}" for name in allowed_collection_names])}

üîç INSTRU√á√ïES RAG:
- Use a fun√ß√£o 'search' para buscar informa√ß√µes nessas bases
- Sempre busque primeiro nas bases antes de dar respostas gen√©ricas  
- Cite as fontes espec√≠ficas quando usar informa√ß√µes das bases
- Se n√£o encontrar informa√ß√µes relevantes, diga claramente que consultou as bases

            """
            full_instructions = f"{collections_context}\n\n{base_instructions}"
            logger.info(f"‚úÖ [AGENT-{agent_id}] INSTRU√á√ïES ATUALIZADAS COM {len(allowed_collection_names)} COLE√á√ïES RAG")
        else:
            full_instructions = base_instructions
            logger.info(f"‚ö†Ô∏è [AGENT-{agent_id}] AGENTE SEM ACESSO A COLE√á√ïES RAG")

        # Listar ferramentas dispon√≠veis para logging
        tool_names = []
        if tools:
            for tool in tools:
                if hasattr(tool, '__name__'):
                    tool_names.append(tool.__name__)
                elif hasattr(tool, 'name'):
                    tool_names.append(tool.name)
                else:
                    tool_names.append(str(type(tool).__name__))
        
        logger.info(f"üîß [AGENT-{agent_id}] FERRAMENTAS DISPON√çVEIS: {tool_names}")
        logger.info(f"üìù [AGENT-{agent_id}] TAMANHO DAS INSTRU√á√ïES: {len(full_instructions)} caracteres")

        # Criar agente Agno
        agent = Agent(
            name=agent_config.get('name', 'Assistant'),
            role=agent_config.get('role', 'AI Assistant'),
            model=OpenAIChat(
                id=agent_config.get('model', 'gpt-4o-mini'),
                temperature=agent_config.get('temperature', 0.7)
            ),
            tools=tools,
            instructions=full_instructions,
            markdown=True,
            structured_outputs=True
        )

        # Cachear agente
        self.active_agents[agent_id] = agent
        logger.info(f"‚úÖ [AGENT-{agent_id}] AGENTE CRIADO E CACHEADO: {agent_config.get('name')}")

        return agent

    def execute_agent_task(
            self,
            agent_config: Dict,
            task: str,
            session_id: Optional[str] = None
    ) -> Dict:
        """
        Executa uma tarefa com um agente espec√≠fico
        """
        start_time = time.time()

        # Criar/recuperar agente
        agent = self.create_agent_instance(agent_config)

        try:
            # Executar tarefa
            response = agent.run(task)

            # Processar resposta
            if hasattr(response, 'content'):
                response_content = response.content
            else:
                response_content = str(response)

            # Extrair ferramentas usadas
            tools_used = []
            if hasattr(response, 'messages') and response.messages:
                for msg in response.messages:
                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                        tools_used.extend([tc.name for tc in msg.tool_calls if hasattr(tc, 'name')])

            execution_time = int((time.time() - start_time) * 1000)

            # Registrar execu√ß√£o
            execution_record = {
                "agent_id": agent_config.get('id'),
                "agent_name": agent_config.get('name'),
                "task": task,
                "response": response_content,
                "tools_used": list(set(tools_used)),
                "execution_time_ms": execution_time,
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "success": True
            }

            self.execution_history.append(execution_record)

            return execution_record

        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)

            error_record = {
                "agent_id": agent_config.get('id'),
                "agent_name": agent_config.get('name'),
                "task": task,
                "error": str(e),
                "execution_time_ms": execution_time,
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "success": False
            }

            self.execution_history.append(error_record)

            return error_record

    def create_agent_team(
            self,
            team_members: List[Dict],
            team_leader_config: Optional[Dict] = None
    ) -> Agent:
        """
        Cria um time de agentes que colaboram em tarefas
        """
        # Criar inst√¢ncias dos membros do time
        member_agents = []

        for member_config in team_members:
            agent = self.create_agent_instance(member_config)
            member_agents.append(agent)

        # Configurar l√≠der do time
        if team_leader_config:
            logger.info(f"üèÜ CRIANDO TIME COM L√çDER: {team_leader_config.get('name')} (ID: {team_leader_config.get('id')})")
            # Usar o agente l√≠der configurado na UI
            leader_agent = self.create_agent_instance(team_leader_config)
            logger.info(f"üìã INSTRU√á√ïES ORIGINAIS DO L√çDER: {leader_agent.instructions[:150] if leader_agent.instructions else 'NENHUMA'}...")
            
            # Criar contexto detalhado sobre os membros do time
            team_context = "\n\n=== VOC√ä √â O L√çDER DESTE TIME ===\n"
            team_context += "Membros do seu time:\n"
            
            for i, member_config in enumerate(team_members, 1):
                member_collections = self.get_agent_collections(member_config.get('id', 0))
                collections_info = ", ".join([c.get('name', '') for c in member_collections]) if member_collections else "Nenhuma"
                
                tools_config = member_config.get('tools_config', [])
                if isinstance(tools_config, str):
                    tools_config = json.loads(tools_config) if tools_config else []
                tools_info = ", ".join(tools_config) if tools_config else "RAG"
                
                member_instructions = member_config.get('instructions', '')
                speciality = member_instructions[:200] + "..." if len(member_instructions) > 200 else member_instructions
                
                team_context += f"""
{i}. {member_config.get('name', 'Agente')} ({member_config.get('role', 'Assistente')})
   - Especialidade: {speciality or 'Assistente geral'}
   - Bases de conhecimento: {collections_info}
   - Ferramentas: {tools_info}
"""
            
            # Criar mapeamento de modelos para especialistas
            model_mapping = {}
            for member_config in team_members:
                member_name = member_config.get('name', '')
                if 'CH570' in member_name or 'CH670' in member_name:
                    model_mapping['CH570'] = member_name
                    model_mapping['CH670'] = member_name
                elif 'A9000' in member_name:
                    model_mapping['A9000'] = member_name
                elif 'A8000' in member_name or 'A8800' in member_name:
                    model_mapping['A8000'] = member_name
                    model_mapping['A8800'] = member_name
                elif 'CH950' in member_name:
                    model_mapping['CH950'] = member_name
            
            available_models = list(model_mapping.keys())
            
            team_context += f"""

üéØ INSTRU√á√ïES DE TRIAGEM OBRIGAT√ìRIAS:

**SUA FUN√á√ÉO:** Voc√™ √© um COORDENADOR DE TRIAGEM, n√£o um t√©cnico.

**REGRA #1 - M√ÅQUINA ESPECIFICADA:**
Se o usu√°rio mencionar um modelo espec√≠fico ({', '.join(available_models)}):
- IMEDIATAMENTE delegue para o especialista correto
- Use: "Vou encaminhar para [NOME_ESPECIALISTA] que √© expert neste modelo"
- Mapeamento dispon√≠vel: {model_mapping}

**REGRA #2 - M√ÅQUINA N√ÉO ESPECIFICADA:**
Se o usu√°rio N√ÉO especificar a m√°quina:
- PARE! N√ÉO tente responder tecnicamente
- Responda: "Para te ajudar melhor, preciso saber qual m√°quina espec√≠fica. Temos especialistas em: {', '.join(available_models)}. Qual modelo voc√™ est√° usando?"
- NUNCA d√™ respostas t√©cnicas gen√©ricas

**EXEMPLOS PR√ÅTICOS:**
- "Problema na CH570" ‚Üí Delegar para {model_mapping.get('CH570', 'Especialista CH570')}
- "Freios com problema" ‚Üí Perguntar: "Em qual m√°quina? ({', '.join(available_models[:3])}...)"

**PROIBIDO:**
- Responder perguntas t√©cnicas sozinho
- Dar solu√ß√µes gen√©ricas
- Tentar adivinhar a m√°quina
"""
            
            # Preservar instru√ß√µes originais do l√≠der
            original_instructions = leader_agent.instructions or ""
            full_instructions = original_instructions + team_context
            
            logger.info(f"üìè TAMANHO INSTRU√á√ïES ORIGINAIS: {len(original_instructions)} chars")
            logger.info(f"üìè TAMANHO CONTEXTO DO TIME: {len(team_context)} chars") 
            logger.info(f"üìè TAMANHO INSTRU√á√ïES FINAIS: {len(full_instructions)} chars")
            logger.info(f"üó∫Ô∏è MAPEAMENTO DE MODELOS: {model_mapping}")
            logger.info(f"üîß CONTEXTO DE TRIAGEM GERADO: {team_context[-800:]}")
            logger.info(f"üë• MEMBROS NO TIME: {len(team_members)} - {[m.get('name') for m in team_members]}")
            
            # Criar time com o l√≠der espec√≠fico
            team = Agent(
                name=leader_agent.name,
                role=leader_agent.role,
                team=member_agents,
                model=leader_agent.model,
                instructions=full_instructions,
                tools=leader_agent.tools if hasattr(leader_agent, 'tools') else [],
                markdown=True,
                show_tool_calls=True
            )
        else:
            # Fallback para l√≠der gen√©rico se n√£o especificado
            leader_model = OpenAIChat(id='gpt-4o-mini')
            
            team = Agent(
                team=member_agents,
                model=leader_model,
                instructions=[
                    "Coordene os agentes do time para resolver a tarefa",
                    "Distribua subtarefas baseado nas especialidades de cada agente",
                    "Sintetize as respostas em uma solu√ß√£o coerente",
                    "Sempre cite qual agente contribuiu com cada parte da resposta"
                ],
                markdown=True,
                show_tool_calls=True
            )

        return team

    def execute_team_task(
            self,
            team_members: List[Dict],
            task: str,
            team_leader_config: Optional[Dict] = None
    ) -> Dict:
        """
        Executa tarefa com um time de agentes
        """
        start_time = time.time()

        try:
            # Criar time
            team = self.create_agent_team(team_members, team_leader_config)
            
            logger.info(f"‚ö° INICIANDO EXECU√á√ÉO DA TAREFA: {task}")
            logger.info(f"ü§ñ AGENTE L√çDER: {team.name} com {len(team.instructions) if hasattr(team, 'instructions') else 'sem'} chars de instru√ß√µes")

            # Executar tarefa
            response = team.run(task)
            
            logger.info(f"üì® RESPOSTA COMPLETA: {str(response)}")
            
            # Verificar se houve delega√ß√£o (m√∫ltiplas mensagens)
            if hasattr(response, 'messages') and response.messages:
                logger.info(f"üí¨ N√öMERO DE MENSAGENS NA CONVERSA: {len(response.messages)}")
                for i, msg in enumerate(response.messages):
                    logger.info(f"  MSG {i+1}: {str(msg)[:200]}...")
            else:
                logger.info(f"‚ö†Ô∏è RESPOSTA SEM MENSAGENS DETALHADAS")

            # Processar resposta
            if hasattr(response, 'content'):
                response_content = response.content
            else:
                response_content = str(response)

            execution_time = int((time.time() - start_time) * 1000)

            return {
                "task": task,
                "team_response": response_content,
                "agents_involved": [m.get('name') for m in team_members],
                "execution_time_ms": execution_time,
                "success": True,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)

            return {
                "task": task,
                "error": str(e),
                "agents_involved": [m.get('name') for m in team_members],
                "execution_time_ms": execution_time,
                "success": False,
                "timestamp": datetime.now().isoformat()
            }

    def execute_team_task_with_context(self, team_id: int, task: str, context_history: List[Dict] = None) -> Dict:
        """
        Executa uma tarefa em equipe considerando o contexto completo da conversa
        Sistema flex√≠vel que suporta diferentes estrat√©gias de delega√ß√£o
        """
        try:
            start_time = time.time()
            logger.info(f"üöÄ [TIME-{team_id}] INICIANDO EXECU√á√ÉO DA TAREFA")
            logger.info(f"üìã [TIME-{team_id}] TAREFA: {task[:200]}...")
            logger.info(f"üìö [TIME-{team_id}] CONTEXTO: {len(context_history) if context_history else 0} mensagens anteriores")
            
            # Buscar team e membros
            team = self.db.query(AgentTeam).filter(AgentTeam.id == team_id).first()
            if not team:
                logger.error(f"‚ùå [TIME-{team_id}] ERRO: Team n√£o encontrado")
                raise ValueError(f"Team {team_id} n√£o encontrado")
            
            logger.info(f"üëë [TIME-{team_id}] TEAM: {team.name} - L√≠der: {team.leader_agent_id}")

            team_members_query = self.db.query(
                TeamMember.agent_id,
                AgentModel.name,
                AgentModel.description,
                AgentModel.role,
                AgentModel.model,
                AgentModel.temperature,
                AgentModel.instructions,
                AgentModel.tools_config
            ).join(AgentModel, TeamMember.agent_id == AgentModel.id).filter(
                TeamMember.team_id == team_id,
                AgentModel.is_active == True
            )

            team_members = []
            for result in team_members_query:
                member_data = {
                    'id': result.agent_id,
                    'name': result.name,
                    'description': result.description,
                    'role': result.role,
                    'model': result.model,
                    'temperature': result.temperature,
                    'instructions': result.instructions,
                    'tools_config': result.tools_config or []
                }
                team_members.append(member_data)
                logger.info(f"üë§ [TIME-{team_id}] MEMBRO: {result.name} (ID: {result.agent_id}) - {result.role}")

            if not team_members:
                logger.error(f"‚ùå [TIME-{team_id}] ERRO: Nenhum membro ativo encontrado")
                raise ValueError(f"Nenhum membro ativo encontrado para o team {team_id}")
            
            logger.info(f"üë• [TIME-{team_id}] MEMBROS CARREGADOS: {len(team_members)} agentes")

            # Buscar l√≠der separadamente (pode n√£o estar nos membros)
            leader_config = None
            if team.leader_agent_id:
                leader = self.db.query(AgentModel).filter(
                    AgentModel.id == team.leader_agent_id,
                    AgentModel.is_active == True
                ).first()
                
                if leader:
                    leader_config = {
                        'id': leader.id,
                        'name': leader.name,
                        'description': leader.description,
                        'role': leader.role,
                        'model': leader.model,
                        'temperature': leader.temperature,
                        'instructions': leader.instructions,
                        'tools_config': leader.tools_config or []
                    }
                    logger.info(f"üëë [TIME-{team_id}] L√çDER CARREGADO: {leader.name} (ID: {leader.id}) - {leader.role}")

            if not leader_config:
                logger.error(f"‚ùå [TIME-{team_id}] ERRO: L√≠der n√£o encontrado ou inativo")
                raise ValueError(f"L√≠der do team {team_id} n√£o encontrado ou inativo")

            # Preparar contexto da conversa para o l√≠der
            context_text = ""
            if context_history:
                context_text = "\\n\\n--- HIST√ìRICO DA CONVERSA ---\\n"
                logger.info(f"üìú [TIME-{team_id}] PROCESSANDO HIST√ìRICO DE {len(context_history)} mensagens:")
                
                for i, msg in enumerate(context_history):
                    msg_type = msg.get('type', 'unknown')
                    content = msg.get('content', '')
                    timestamp = msg.get('timestamp', '')
                    sender_info = msg.get('metadata', {}).get('sender', 'unknown')
                    
                    logger.info(f"   üìù [TIME-{team_id}] MSG {i+1}: [{msg_type.upper()}] {sender_info} -> {content[:100]}...")
                    
                    if msg_type == 'user':
                        context_text += f"[USU√ÅRIO]: {content}\\n"
                    elif msg_type == 'team':
                        context_text += f"[EQUIPE]: {content}\\n"
                    elif msg_type == 'agent':
                        context_text += f"[AGENTE]: {content}\\n"
                
                context_text += "--- FIM DO HIST√ìRICO ---\\n\\n"
                logger.info(f"üìú [TIME-{team_id}] CONTEXTO PREPARADO: {len(context_text)} caracteres")

            # Determinar estrat√©gia de delega√ß√£o baseada no time
            delegation_strategy = self._determine_delegation_strategy(team, team_members, task)
            logger.info(f"üéØ [TIME-{team_id}] ESTRAT√âGIA DE DELEGA√á√ÉO: {delegation_strategy}")

            # Executar com base na estrat√©gia
            if delegation_strategy == "specific_model_matching":
                return self._execute_with_model_matching(team_id, team, team_members, leader_config, task, context_text, context_history, start_time)
            else:
                return self._execute_with_flexible_delegation(team_id, team, team_members, leader_config, task, context_text, context_history, start_time)

        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            
            logger.error(f"üí• [TIME-{team_id}] ERRO NA EXECU√á√ÉO: {str(e)}")
            logger.error(f"‚è±Ô∏è [TIME-{team_id}] TEMPO AT√â ERRO: {execution_time}ms")
            
            error_agents = [m.get('name') for m in team_members] if 'team_members' in locals() else []
            logger.error(f"üë• [TIME-{team_id}] AGENTES DISPON√çVEIS NO MOMENTO DO ERRO: {error_agents}")

            return {
                "task": task,
                "error": str(e),
                "agents_involved": error_agents,
                "execution_time_ms": execution_time,
                "success": False,
                "timestamp": datetime.now().isoformat()
            }

    def _determine_delegation_strategy(self, team, team_members: List[Dict], task: str) -> str:
        """
        Determina qual estrat√©gia de delega√ß√£o usar baseada no time e contexto
        """
        # Verificar se algum membro tem padr√£o espec√≠fico de m√°quinas agr√≠colas no nome
        machine_patterns = ['CH570', 'CH670', 'A9000', 'A8000', 'A8800', 'A8810', 'A9900', 'CH950', 'TC', 'Plantio']
        
        for member in team_members:
            member_name = member.get('name', '')
            if any(pattern in member_name for pattern in machine_patterns):
                logger.info(f"üîß [TEAM] DETECTADO TIME COM ESPECIALISTAS EM M√ÅQUINAS: {member_name}")
                return "specific_model_matching"
        
        # Estrat√©gia flex√≠vel para todos os outros casos
        logger.info(f"üåü [TEAM] USANDO ESTRAT√âGIA FLEX√çVEL PARA TIME: {team.name}")
        return "flexible_delegation"

    def _execute_with_model_matching(self, team_id: int, team, team_members: List[Dict], 
                                   leader_config: Dict, task: str, context_text: str,
                                   context_history: List[Dict], start_time: float) -> Dict:
        """
        Execu√ß√£o com estrat√©gia espec√≠fica para m√°quinas agr√≠colas (l√≥gica original)
        """
        logger.info(f"üöú [TIME-{team_id}] EXECUTANDO COM ESTRAT√âGIA ESPEC√çFICA DE M√ÅQUINAS")
        
        # Criar mapeamento de modelos espec√≠ficos
        model_mapping = {}
        for member_config in team_members:
            member_name = member_config.get('name', '')
            if 'CH570' in member_name or 'CH670' in member_name:
                model_mapping['CH570'] = member_name
                model_mapping['CH670'] = member_name
            elif 'A9000' in member_name:
                model_mapping['A9000'] = member_name
            elif 'A8000' in member_name or 'A8800' in member_name:
                model_mapping['A8000'] = member_name
                model_mapping['A8800'] = member_name
            elif 'CH950' in member_name:
                model_mapping['CH950'] = member_name
            elif 'TC' in member_name:
                model_mapping['TC'] = member_name
            elif 'Plantio' in member_name or 'plantio' in member_name:
                model_mapping['Plantio'] = member_name

        # Verificar se deve delegar baseado no contexto
        should_delegate = False
        target_specialist = None
        
        # Verificar se a pergunta atual ou contexto menciona modelo espec√≠fico
        # IMPORTANTE: Incluir apenas mensagens do usu√°rio para evitar detectar modelos nas pr√≥prias respostas
        combined_text = task.lower()
        if context_history:
            for msg in context_history[-3:]:  # √öltimas 3 mensagens para contexto
                if msg.get('type', '') == 'user':  # Apenas mensagens do usu√°rio
                    combined_text += " " + msg.get('content', '').lower()
        
        # Buscar por modelos espec√≠ficos no texto (ordenado por especificidade)
        logger.info(f"üîç [TIME-{team_id}] ANALISANDO PARA DELEGA√á√ÉO: '{combined_text[:200]}...'")
        
        # Ordenar por tamanho decrescente para priorizar matches mais espec√≠ficos
        sorted_models = sorted(model_mapping.items(), key=lambda x: len(x[0]), reverse=True)
        logger.info(f"üó∫Ô∏è [TIME-{team_id}] ORDEM DE TESTE: {[k for k, v in sorted_models]}")
        
        for model_key, specialist_name in sorted_models:
            # Fazer match mais preciso com word boundaries
            pattern = r'\b' + re.escape(model_key.lower()) + r'\b'
            match_result = re.search(pattern, combined_text.lower())
            if match_result:
                should_delegate = True
                target_specialist = next((m for m in team_members if m['name'] == specialist_name), None)
                logger.info(f"‚úÖ [TIME-{team_id}] MODELO DETECTADO: {model_key} -> DELEGANDO PARA: {specialist_name}")
                logger.info(f"üîé [TIME-{team_id}] MATCH ENCONTRADO: '{match_result.group()}' na posi√ß√£o {match_result.start()}-{match_result.end()}")
                logger.info(f"üìù [TIME-{team_id}] CONTEXTO DO MATCH: '...{combined_text[max(0, match_result.start()-10):match_result.end()+10]}...'")
                break
            else:
                logger.info(f"‚ùå [TIME-{team_id}] MODELO {model_key} N√ÉO ENCONTRADO (pattern: '{pattern}')")

        if should_delegate and target_specialist:
            return self._execute_specialist_directly(team_id, target_specialist, task, context_text, start_time, leader_config)
        else:
            # L√≠der responde com contexto de triagem espec√≠fica
            leader_context = f"""
            {context_text}
            Voc√™ √© o l√≠der de uma equipe de especialistas em m√°quinas agr√≠colas. 
            
            Para esta tarefa: "{task}"
            
            Especialistas dispon√≠veis: {', '.join(model_mapping.keys()) if model_mapping else 'Nenhum'}
            
            Se n√£o conseguir identificar a m√°quina espec√≠fica, pergunte qual modelo o usu√°rio est√° usando.
            Se conseguir identificar, explique que voc√™ est√° encaminhando para o especialista apropriado.
            """
            return self._execute_leader_response(team_id, leader_config, leader_context, task, start_time)

    def _execute_with_flexible_delegation(self, team_id: int, team, team_members: List[Dict],
                                        leader_config: Dict, task: str, context_text: str,
                                        context_history: List[Dict], start_time: float) -> Dict:
        """
        Execu√ß√£o flex√≠vel que permite diferentes estrat√©gias de delega√ß√£o
        """
        logger.info(f"üåü [TIME-{team_id}] EXECUTANDO COM ESTRAT√âGIA FLEX√çVEL")
        
        # Encontrar o melhor agente baseado na tarefa e compet√™ncias
        best_agent = self._find_best_agent_for_task(team_members, task, context_text)
        
        if best_agent:
            logger.info(f"üéØ [TIME-{team_id}] MELHOR AGENTE ENCONTRADO: {best_agent['name']} - {best_agent['role']}")
            return self._execute_specialist_directly(team_id, best_agent, task, context_text, start_time, leader_config)
        else:
            # L√≠der coordena colaborativamente
            leader_context = f"""
            {context_text}
            
            Voc√™ √© o l√≠der desta equipe. Para a tarefa: "{task}"
            
            Membros dispon√≠veis:
            {chr(10).join([f"- {m.get('name')}: {m.get('role', 'Assistente')} - {m.get('description', 'Sem descri√ß√£o')[:100]}" for m in team_members])}
            
            Analise a tarefa e:
            1. Se algum membro espec√≠fico seria ideal, mencione que est√° delegando para ele
            2. Se for uma quest√£o geral, responda diretamente usando sua expertise de lideran√ßa
            3. Se precisar de informa√ß√µes espec√≠ficas, coordene a resposta baseada nas compet√™ncias da equipe
            
            Sua fun√ß√£o √© coordenar e fornecer a melhor resposta poss√≠vel.
            """
            return self._execute_leader_response(team_id, leader_config, leader_context, task, start_time)

    def _find_best_agent_for_task(self, team_members: List[Dict], task: str, context: str) -> Optional[Dict]:
        """
        Encontra o melhor agente para uma tarefa espec√≠fica baseado em compet√™ncias
        """
        task_lower = task.lower()
        
        # Pontua√ß√£o por agente baseada na relev√¢ncia
        agent_scores = []
        
        for agent in team_members:
            score = 0
            
            # Pontua√ß√£o baseada na descri√ß√£o/especialidade
            description = agent.get('description', '').lower()
            instructions = agent.get('instructions', '').lower()
            role = agent.get('role', '').lower()
            
            # Verificar correspond√™ncias nas instru√ß√µes e descri√ß√µes
            combined_agent_info = f"{description} {instructions} {role}"
            
            # Palavras-chave da tarefa presentes na descri√ß√£o do agente
            task_words = set(task_lower.split())
            agent_words = set(combined_agent_info.split())
            common_words = task_words.intersection(agent_words)
            score += len(common_words) * 2
            
            # Pontua√ß√£o extra se o agente tem cole√ß√µes RAG associadas
            agent_collections = self.get_agent_collections(agent.get('id', 0))
            if agent_collections:
                score += len(agent_collections) * 3
            
            if score > 0:
                agent_scores.append((agent, score))
                logger.info(f"üìä [AGENT-MATCH] {agent['name']}: score {score} (palavras comuns: {len(common_words)}, cole√ß√µes: {len(agent_collections)})")
        
        # Retornar o agente com maior pontua√ß√£o, se houver uma diferen√ßa significativa
        if agent_scores:
            agent_scores.sort(key=lambda x: x[1], reverse=True)
            best_agent, best_score = agent_scores[0]
            
            # S√≥ delegar se o score for significativo (> 3) e melhor que os outros
            if best_score >= 3:
                if len(agent_scores) == 1 or best_score > agent_scores[1][1] * 1.5:
                    return best_agent
        
        return None

    def _execute_specialist_directly(self, team_id: int, specialist: Dict, task: str, 
                                   context_text: str, start_time: float, leader_config: Dict) -> Dict:
        """
        Executa um especialista espec√≠fico diretamente
        """
        logger.info(f"üë®‚Äçüîß [TIME-{team_id}] EXECUTANDO ESPECIALISTA: {specialist['name']}")
        
        # BUSCA RAG AUTOM√ÅTICA ANTES DA EXECU√á√ÉO
        rag_context = ""
        agent_id = specialist['id']
        
        # Buscar cole√ß√µes RAG do agente especialista
        agent_collections = self.get_agent_collections(agent_id)
        if agent_collections:
            logger.info(f"üîç [TIME-{team_id}] FAZENDO BUSCA RAG AUTOM√ÅTICA PARA ESPECIALISTA...")
            collection_names = [col['name'] for col in agent_collections]
            logger.info(f"üìö [TIME-{team_id}] COLE√á√ïES DISPON√çVEIS: {collection_names}")
            
            # Criar inst√¢ncia RAG tempor√°ria para busca
            temp_rag = QdrantRAGTool(self.qdrant_service, collection_names, self.db)
            
            try:
                # Fazer busca autom√°tica com termos da tarefa
                initial_results = temp_rag.search(task, limit=5)
                if initial_results and not any('error' in str(r) for r in initial_results):
                    logger.info(f"‚úÖ [TIME-{team_id}] BUSCA RAG CONCLU√çDA: {len(initial_results)} resultados")
                    rag_context = "\n\nüóÑÔ∏è INFORMA√á√ïES DAS BASES DE CONHECIMENTO:\n"
                    for i, result in enumerate(initial_results[:3]):
                        content = result.get('text', result.get('content', ''))
                        rag_context += f"{i+1}. {content[:500]}...\n\n"
                    rag_context += "üìã Use essas informa√ß√µes como base para sua resposta.\n"
                else:
                    logger.warning(f"‚ö†Ô∏è [TIME-{team_id}] BUSCA RAG SEM RESULTADOS V√ÅLIDOS")
            except Exception as e:
                logger.error(f"‚ùå [TIME-{team_id}] ERRO NA BUSCA RAG: {e}")
        else:
            logger.info(f"‚ÑπÔ∏è [TIME-{team_id}] ESPECIALISTA SEM COLE√á√ïES RAG ASSOCIADAS")

        specialist_context = f"""
        {context_text}
        
        Voc√™ √© {specialist['name']} - {specialist.get('role', 'Especialista')}.
        
        Tarefa: {task}
        
        {rag_context}
        
        Forne√ßa uma resposta t√©cnica detalhada baseada na sua especialidade e conhecimento.
        """
        
        specialist_agent = self._get_or_create_agent(specialist['id'], specialist)
        response = specialist_agent.run(specialist_context)
        
        # Processar resposta
        response_content = response.content if hasattr(response, 'content') else str(response)
        execution_time = int((time.time() - start_time) * 1000)
        
        logger.info(f"‚úÖ [TIME-{team_id}] ESPECIALISTA RESPONDEU: {len(response_content)} caracteres")
        
        # Capturar informa√ß√µes de RAG para resposta
        rag_info = {"rag_used": False, "searches": []}
        if rag_context:
            rag_info = {
                "rag_used": True,
                "searches": [{"query": task[:100], "results_count": len(initial_results) if 'initial_results' in locals() else 0}],
                "total_searches": 1,
                "total_results": len(initial_results) if 'initial_results' in locals() else 0,
                "collections_searched": collection_names if 'collection_names' in locals() else []
            }
            logger.info(f"üóÑÔ∏è [TIME-{team_id}] RAG USADO: {rag_info['total_results']} resultados de {len(rag_info['collections_searched'])} cole√ß√µes")
        
        return {
            "task": task,
            "team_response": response_content,
            "agents_involved": [leader_config['name'], specialist['name']],
            "execution_time_ms": execution_time,
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "delegation_type": "specialist_direct",
            "rag_info": rag_info
        }

    def _execute_leader_response(self, team_id: int, leader_config: Dict, leader_context: str, task: str, start_time: float) -> Dict:
        """
        Executa resposta direta do l√≠der
        """
        logger.info(f"üëë [TIME-{team_id}] EXECUTANDO L√çDER: {leader_config['name']}")
        
        leader_agent = self._get_or_create_agent(leader_config['id'], leader_config)
        response = leader_agent.run(leader_context)
        
        # Processar resposta
        response_content = response.content if hasattr(response, 'content') else str(response)
        execution_time = int((time.time() - start_time) * 1000)
        
        logger.info(f"‚úÖ [TIME-{team_id}] L√çDER RESPONDEU: {len(response_content)} caracteres")
        
        return {
            "task": task,
            "team_response": response_content,
            "agents_involved": [leader_config['name']],
            "execution_time_ms": execution_time,
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "delegation_type": "leader_direct"
        }

    def _get_or_create_agent(self, agent_id: int, agent_config: Dict):
        """
        Obt√©m ou cria um agente Agno baseado na configura√ß√£o
        """
        if agent_id in self.active_agents:
            return self.active_agents[agent_id]
        
        # Buscar cole√ß√µes permitidas para o agente
        allowed_collections = self.get_agent_collections(agent_id)
        collection_names = [col['name'] for col in allowed_collections]
        
        # Criar ferramenta RAG se h√° cole√ß√µes dispon√≠veis
        tools = []
        if collection_names:
            logger.info(f"üóÑÔ∏è [AGENT-{agent_id}] COLE√á√ïES RAG DISPON√çVEIS: {collection_names}")
            rag_tool = QdrantRAGTool(
                qdrant_service=self.qdrant_service,
                allowed_collections=collection_names,
                db=self.db
            )
            tools.append(rag_tool.search)  # Adicionar o m√©todo search como ferramenta
            logger.info(f"‚úÖ [AGENT-{agent_id}] FERRAMENTA RAG CRIADA COM {len(collection_names)} COLE√á√ïES")
        else:
            logger.info(f"‚ö†Ô∏è [AGENT-{agent_id}] NENHUMA COLE√á√ÉO RAG ASSOCIADA")
        
        # Adicionar ferramentas extras baseadas na configura√ß√£o
        tools_config = agent_config.get('tools_config', [])
        if isinstance(tools_config, list):
            for tool_name in tools_config:
                if tool_name == 'duckduckgo':
                    tools.append(DuckDuckGoTools())
                elif tool_name == 'reasoning':
                    tools.append(ReasoningTools())
        
        # Criar agente Agno
        agent = Agent(
            model=OpenAIChat(
                id=agent_config.get('model', 'gpt-4o-mini'),
                temperature=agent_config.get('temperature', 0.7)
            ),
            instructions=agent_config.get('instructions', ''),
            tools=tools,
            debug_mode=False,
            markdown=True
        )
        
        # Cache do agente
        self.active_agents[agent_id] = agent
        return agent

    def clear_agent_cache(self, agent_id: Optional[int] = None):
        """
        Limpa cache de agentes ativos
        """
        if agent_id:
            if agent_id in self.active_agents:
                del self.active_agents[agent_id]
        else:
            self.active_agents.clear()

    def get_execution_stats(self) -> Dict:
        """
        Retorna estat√≠sticas de execu√ß√£o
        """
        if not self.execution_history:
            return {
                "total_executions": 0,
                "success_rate": 0,
                "avg_execution_time_ms": 0,
                "tools_usage": {}
            }

        successful = [e for e in self.execution_history if e.get('success')]

        # Calcular uso de ferramentas
        tools_usage = {}
        for execution in successful:
            tools_list = execution.get('tools_used', []) or []
            for tool in tools_list:
                tools_usage[tool] = tools_usage.get(tool, 0) + 1

        avg_time = sum(e.get('execution_time_ms', 0) for e in self.execution_history) / len(self.execution_history)

        return {
            "total_executions": len(self.execution_history),
            "successful_executions": len(successful),
            "success_rate": len(successful) / len(self.execution_history) * 100,
            "avg_execution_time_ms": int(avg_time),
            "tools_usage": tools_usage,
            "last_execution": self.execution_history[-1] if self.execution_history else None
        }


# Fun√ß√µes auxiliares para endpoints FastAPI

async def create_agent(db: Session, agent_data: Dict) -> Dict:
    """
    Cria novo agente no banco de dados
    """
    query = text("""
        INSERT INTO agents (name, description, role, model, temperature, instructions, tools_config)
        VALUES (:name, :description, :role, :model, :temperature, :instructions, :tools_config)
        RETURNING id
    """)

    result = db.execute(query, {
        "name": agent_data.get('name'),
        "description": agent_data.get('description'),
        "role": agent_data.get('role'),
        "model": agent_data.get('model', 'gpt-4o-mini'),
        "temperature": agent_data.get('temperature', 0.7),
        "instructions": agent_data.get('instructions', ''),
        "tools_config": json.dumps(agent_data.get('tools_config', []))
    })

    db.commit()
    agent_id = result.scalar()

    return {"id": agent_id, "message": "Agente criado com sucesso"}


async def assign_collection_to_agent(
        db: Session,
        agent_id: int,
        collection_id: int,
        access_level: str = "read",
        priority: int = 0
) -> Dict:
    """
    Relaciona agente com cole√ß√£o RAG
    """
    # Verificar se relacionamento j√° existe
    check_query = text("""
        SELECT 1 FROM agent_collections 
        WHERE agent_id = :agent_id AND collection_id = :collection_id
    """)

    exists = db.execute(check_query, {
        "agent_id": agent_id,
        "collection_id": collection_id
    }).scalar()

    if exists:
        # Atualizar relacionamento existente
        update_query = text("""
            UPDATE agent_collections 
            SET access_level = :access_level, priority = :priority
            WHERE agent_id = :agent_id AND collection_id = :collection_id
        """)

        db.execute(update_query, {
            "agent_id": agent_id,
            "collection_id": collection_id,
            "access_level": access_level,
            "priority": priority
        })
    else:
        # Criar novo relacionamento
        insert_query = text("""
            INSERT INTO agent_collections (agent_id, collection_id, access_level, priority)
            VALUES (:agent_id, :collection_id, :access_level, :priority)
        """)

        db.execute(insert_query, {
            "agent_id": agent_id,
            "collection_id": collection_id,
            "access_level": access_level,
            "priority": priority
        })

    db.commit()

    return {"message": "Cole√ß√£o associada ao agente com sucesso"}